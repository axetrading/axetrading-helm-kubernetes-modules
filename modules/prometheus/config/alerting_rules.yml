groups:
- name: BlackBox
  rules:
  - alert: BlackboxProbeFail
    expr: avg_over_time(probe_success[10m]) < 0.2
    for: 2m
    labels:
      severity: critical
    annotations:
      description: "Check for {{ $labels.instance }} failed."
  - alert: HighLatency
    expr: avg_over_time(probe_duration_seconds[10m]) > 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      description: "High latency detected for {{ $labels.instance }}."
  - alert: HttpProbeSlow
    expr: sum by (instance) (probe_http_duration_seconds) > 1
    for: 2m
    labels:
      severity: warning
    annotations:
      description: "{{ $labels.instance }} takes {{ $value }} seconds to respond."
      summary: "Http probe takes {{ $value }} seconds to respond."
  - alert: HttpCertExpiresVerySoon
    expr: probe_ssl_earliest_cert_expiry - time() < 86400
    for: 2m
    labels:
      severity: critical
    annotations:
      description: "Certificate for {{ $labels.instance }} expires in less than 24 hours."
      summary: "Certificate for {{ $labels.instance }} expires in less than 24 hours."
  
- name: Kubernetes
  rules:
  - alert: PodFailure
    expr: kube_pod_container_status_waiting_reason{reason="ErrImagePull"} > 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Pod is experiencing image pull error"
      description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is unable to pull the image"
  - alert: CrashLoopBackOff
    expr: kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff"} > 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Pod is crashing continuously"
      description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is in a crash loop"
  - alert: PodRestarts
    expr: increase(kube_pod_container_status_restarts_total[5m]) > 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Pod restarts"
      description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has restarted"
  - alert: ContainerRestart
    expr: rate(kube_pod_container_status_last_terminated_reason{ reason !="Completed"}[5m]) * 300 > 1
    for: 3m
    labels:
      severity: warning
    annotations:
      description: "Container {{ $labels.container }} in Pod {{$labels.namespace}}/{{$labels.pod}} failed more than once times during last 5min ({{$labels.reason}})."
      runbook: "https://containersolutions.github.io/runbooks/posts/kubernetes/crashloopbackoff/"
  - alert: InitContainerStatusWaiting
    expr: kube_pod_init_container_status_waiting_reason{reason!="ContainerCreating"} > 0
    for: 2m
    labels:
      severity: critical
    annotations:
      runbook: "https://containersolutions.github.io/runbooks/posts/kubernetes/0-nodes-available-insufficient/"
      description: "Container {{$labels.namespace}}/{{ $labels.container }} {{ $labels.reason }}."
  - alert: ContainerStatusWaiting
    expr: kube_pod_container_status_waiting_reason{reason!="ContainerCreating"} > 0
    for: 2m
    labels:
      severity: critical
    annotations:
      runbook: "https://containersolutions.github.io/runbooks/posts/kubernetes/0-nodes-available-insufficient/"
      description: "Container {{$labels.namespace}}/{{ $labels.container }} {{ $labels.reason }}."
  - alert: ContainerFailed
    expr: sum by (namespace, pod, phase) (max by(namespace, pod, phase) (kube_pod_status_phase{namespace=~".*",phase=~"Unknown|Error|Failed"}) * on(namespace, pod) group_left(owner_kind) max by(namespace, pod, owner_kind) (kube_pod_owner{owner_kind!="Job"})) > 0
    for: 5m
    labels:
      severity: critical
    annotations:
      runbook: "https://containersolutions.github.io/runbooks/posts/kubernetes/crashloopbackoff/"
      description: "Pod {{$labels.namespace}}/{{ $labels.pod }} failed ({{ $labels.phase }})."
  - alert: KubernetesContainerOomKiller
    expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
    for: 2m
    labels:
      severity: warning
    annotations:
      description: "Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes."
  - alert: KubernetesPodPending
    expr: kube_pod_status_phase{phase="Pending"} > 0
    for: 10m
    labels:
      severity: critical
    annotations:
      description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is pending"
  - alert: KubernetesPersistentvolumeclaimPending
    expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
    for: 2m
    labels:
      severity: warning
    annotations:
      description: "PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending"
  - alert: PrometheusNotConnectedToAlertmanager
    expr: prometheus_notifications_alertmanagers_discovered < 1
    for: 2m
    labels:
      severity: critical
    annotations:
      description: "Prometheus cannot connect the alertmanager"
  - alert: PrometheusTargetEmpty
    expr: prometheus_sd_discovered_targets == 0
    for: 2m
    labels:
      severity: critical
    annotations:
      description: "Prometheus has no target in service discovery\n  VALUE = {{ $value }}"

- name: Nodes
  rules:
  - alert: OutOfDiskSpace
    expr: node_filesystem_free_bytes / node_filesystem_size_bytes < 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      description: "Disk is almost full (< 10% left)\n  VALUE = {{ $value }}"
  - alert: HighCPU
    expr: (100 * (1 - avg by(nodename) (irate(node_cpu_seconds_total{job="kubernetes-kube-state",mode="idle"}[5m])))) > 95
    for: 1h
    labels:
      severity: warning
    annotations:
      description: "CPU above 95%\n  VALUE = {{ $value }}"
  - alert: HostUnusualDiskReadLatency
    expr: rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 0.1 and rate(node_disk_reads_completed_total[1m]) > 0
    for: 2m
    labels:
      severity: warning
    annotations:
      description: "Disk latency is growing (read operations > 100ms)\n  VALUE = {{ $value }}"
  - alert: HostUnusualDiskWriteRate
    expr: sum by (instance) (rate(node_disk_written_bytes_total[2m])) / 1024 / 1024 > 50
    for: 2m
    labels:
      severity: warning
    annotations:
      description: "Disk is probably writing too much data (> 50 MB/s)\n  VALUE = {{ $value }}"
  - alert: HostOutOfMemory
    expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: Host out of memory (instance {{ $labels.instance }})
      description: Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}
  - alert: HostOomKillDetected
    expr: increase(node_vmstat_oom_kill[1m]) > 0
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: Host OOM kill detected (instance {{ $labels.instance }})
      description: OOM kill detected\n  VALUE = {{ $value }}
  - alert: HostDiskWillFillIn24Hours
    expr: (node_filesystem_avail_bytes{fstype=~"xfs"} * 100) / node_filesystem_size_bytes{fstype=~"xfs"} < 10 and ON (instance, device, mountpoint) predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly{fstype=~"xfs"} == 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: Host disk will fill in 24 hours (instance {{ $labels.instance }})
      description: Filesystem is predicted to run out of space within the next 24 hours at current write rate\n  VALUE = {{ $value }}
  - alert: NodeFilesystemOutOfSpace
    expr: node_filesystem_avail_bytes{fstype=~"ext.|xfs"} / node_filesystem_size_bytes{fstype=~"ext.|xfs"} * 100 < 5 and node_filesystem_readonly{fstype=~"ext.|xfs"} == 0
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: Filesystem on node {{ $labels.node }} is almost full
      description: Filesystem on node {{ $labels.node }} having IP {{ $labels.instance }} has only {{ $value }}% available space left on drive {{ $labels.device }}